{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emely3h/Geospatial_ML/blob/main/scripts/get_stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Prepare Colab, Define Constants"
      ],
      "metadata": {
        "id": "TQiNFtcib6wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osm1lHOLb-Is",
        "outputId": "5f5ae2cd-eabd-41e8-c988-166dbe1b0771"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#! ls\n",
        "%cd drive/MyDrive/MachineLearning/\n",
        "#! git clone https://github.com/emely3h/Geospatial_ML.git\n",
        "%cd Geospatial_ML\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV1KZvqMb_6S",
        "outputId": "08a9cf22-1d5a-4e4f-a0e3-b2541ad6bdd3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/15HUD3sGdfvxy5Y_bjvuXgrzwxt7TzRfm/MachineLearning\n",
            "/content/drive/.shortcut-targets-by-id/15HUD3sGdfvxy5Y_bjvuXgrzwxt7TzRfm/MachineLearning/Geospatial_ML\n",
            "data_exploration  experiments\t     models\t   pyproject.toml    scripts\n",
            "docs\t\t  image_processing   poetry.lock   README.md\t     sripts\n",
            "evaluation\t  metrics_bug.ipynb  prepare_data  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "from keras.utils import Sequence\n",
        "from data_exploration.mask_stats import Mask_Stats\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import jaccard_score, recall_score, precision_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "0FB7ZXQkcKB_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EvaluationMetrics:\n",
        "    def __init__(self, iou, recall, precision, f1, accuracy):\n",
        "\n",
        "        self.iou_invalid = iou[0]\n",
        "        self.iou_valid = iou[1]\n",
        "        self.iou_land = iou[2]\n",
        "        self.mean_iou = iou.sum()/3\n",
        "\n",
        "        self.precision_invalid = precision[0]\n",
        "        self.precision_valid = precision[1]\n",
        "        self.precision_land = precision[2]\n",
        "        self.mean_precision = precision.sum()/3\n",
        "\n",
        "        self.recall_invalid = recall[0]\n",
        "        self.recall_valid = recall[1]\n",
        "        self.recall_land = recall[2]\n",
        "        self.mean_recall = recall.sum()/3\n",
        "\n",
        "        self.f1_invalid = f1[0]\n",
        "        self.f1_valid = f1[1]\n",
        "        self.f1_land = f1[2]\n",
        "        self.mean_f1 = f1.sum()/3\n",
        "\n",
        "        self.mean_accuracy = accuracy\n",
        "\n",
        "    def print_metrics(self):\n",
        "        print(f\"mean iou: {self.mean_iou}\")\n",
        "        print(f\"iou invalid: {self.iou_invalid}\")\n",
        "        print(f\"iou valid: {self.iou_valid}\")\n",
        "        print(f\"iou land: {self.iou_land}\\n\")\n",
        "\n",
        "        print(f\"mean precision: {self.mean_precision}\")\n",
        "        print(f\"precision_invalid: {self.precision_invalid}\")\n",
        "        print(f\"precision_valid: {self.precision_valid}\")\n",
        "        print(f\"precision_land: {self.precision_land}\\n\")\n",
        "\n",
        "        print(f\"mean recall: {self.mean_recall}\")\n",
        "        print(f\"recall_invalid: {self.recall_invalid}\")\n",
        "        print(f\"recall_valid: {self.recall_valid}\")\n",
        "        print(f\"recall_land: {self.recall_land}\\n\")\n",
        "\n",
        "        print(f\"mean f1: {self.mean_f1}\")\n",
        "        print(f\"f1_invalid: {self.f1_invalid}\")\n",
        "        print(f\"f1_valid: {self.f1_valid}\")\n",
        "        print(f\"f1_land: {self.f1_land}\\n\")\n",
        "\n",
        "        print(f\"mean accuracy: {self.mean_accuracy}\")"
      ],
      "metadata": {
        "id": "znvE1OOCDYiw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric calculation"
      ],
      "metadata": {
        "id": "n0lCj9pmEXLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_tiles = 11121\n",
        "train_tiles = 6672\n",
        "test_val_tiles = 2224\n",
        "data_path = \"../data_colab/256_256\"\n",
        "experiment = \"experiment_8\"\n",
        "batch_size = 32\n",
        "tile_size = 256\n",
        "step_size = 25\n",
        "file_name = \"5_3_layers_64_128_256_512_1024\""
      ],
      "metadata": {
        "id": "S2dxthwRWXTI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "for dataset in splits:\n",
        "  print(f'starting with the {dataset} set.')\n",
        "  true = np.memmap(os.path.join(data_path, f\"{dataset}_split_y.npy\"), mode=\"r\", shape=(test_val_tiles, 256, 256), dtype=np.uint8)\n",
        "  true = np.copy(true)\n",
        "  pred = np.memmap(f\"../models/{experiment}/predictions/pred_{dataset}_{file_name}.npy\", mode=\"r\", shape=(test_val_tiles, 256, 256, 3), dtype=np.float32)\n",
        "  pred = np.copy(pred)\n",
        "  pred = np.argmax(pred, axis=-1).astype(np.uint8)\n",
        "\n",
        "  pred = pred.flatten()\n",
        "  true = true.flatten()\n",
        "\n",
        "  print(true.shape)\n",
        "  print(type(true[0]))\n",
        "  print(np.max(true))\n",
        "  print(np.min(true))\n",
        "\n",
        "  print(pred.shape)\n",
        "  print(type(pred[0]))\n",
        "  print(np.max(pred))\n",
        "  print(np.min(pred))\n",
        "\n",
        "  print('start calculate iou...')\n",
        "  iou = jaccard_score(true, pred, average=None)\n",
        "  print('start calculate recall...')\n",
        "  recall = recall_score(true, pred, average=None)\n",
        "  print('start calculate precision...')\n",
        "  precision = precision_score(true, pred, average=None)\n",
        "  print('start calculate f1...')\n",
        "  f1 = f1_score(true, pred, average=None)\n",
        "  print('start calculate accuracy...')\n",
        "  accuracy = accuracy_score(true, pred)\n",
        "\n",
        "  metrics = EvaluationMetrics(iou, recall, precision, f1, accuracy)\n",
        "\n",
        "  with open(f\"../metrics/{experiment}/metrics_{dataset}_{file_name}.pkl\", 'wb') as file:\n",
        "    pickle.dump(metrics, file)\n",
        "  print('saving complete')\n",
        "  print()\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "2BvVasjlBuKI",
        "outputId": "e7e26969-9a1b-482e-fd1b-5e18a09ddfc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting with the train set.\n",
            "(145752064,)\n",
            "<class 'numpy.uint8'>\n",
            "2\n",
            "0\n",
            "(145752064,)\n",
            "<class 'numpy.uint8'>\n",
            "2\n",
            "0\n",
            "start calculate iou...\n",
            "start calculate recall...\n",
            "start calculate precision...\n",
            "start calculate f1...\n",
            "start calculate accuracy...\n",
            "saving complete\n",
            "\n",
            "\n",
            "starting with the val set.\n",
            "(145752064,)\n",
            "<class 'numpy.uint8'>\n",
            "2\n",
            "0\n",
            "(145752064,)\n",
            "<class 'numpy.uint8'>\n",
            "2\n",
            "0\n",
            "start calculate iou...\n",
            "start calculate recall...\n",
            "start calculate precision...\n",
            "start calculate f1...\n",
            "start calculate accuracy...\n",
            "saving complete\n",
            "\n",
            "\n",
            "starting with the test set.\n",
            "(145752064,)\n",
            "<class 'numpy.uint8'>\n",
            "2\n",
            "0\n",
            "(145752064,)\n",
            "<class 'numpy.uint8'>\n",
            "2\n",
            "0\n",
            "start calculate iou...\n",
            "start calculate recall...\n",
            "start calculate precision...\n",
            "start calculate f1...\n",
            "start calculate accuracy...\n",
            "saving complete\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}