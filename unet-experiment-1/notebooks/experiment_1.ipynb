{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emely3h/Geospatial_ML/blob/main/unet-experiment-1/notebooks/experiment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net Experiement 1: Exploring variance/ randomness"
      ],
      "metadata": {
        "collapsed": false,
        "id": "anbA9K1ubSE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When running the exact same model with the exact same dataset we get slightly different results each time due to randomness and variability involved in the training process.\n",
        "the variance refers to \n",
        "The goal of this notebook is to evaluate the variability in the results obtained from different training runs on the same dataset We will use the exact same setup and dataset as in the unet notebook and execute 10 training runs."
      ],
      "metadata": {
        "id": "D-HUQ5YGbW2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Helper Classes"
      ],
      "metadata": {
        "id": "rJznpxWwbvFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "\n",
        "\n",
        "class EvaluationMetrics:\n",
        "    \"\"\"\n",
        "        This class calculates and summarizes evaluation metrics based on the predicted and true labels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x_train, x_val, x_test, y_train, y_val, y_test, y_pred, dataset, training_dates, validation_dates, testing_dates, tile_size, step_size,\n",
        "                 run_count):\n",
        "       \n",
        "        self.y_pred = y_pred\n",
        "        if dataset == 'training':\n",
        "          self.y_true = y_train\n",
        "        elif dataset == 'validation':\n",
        "          self.y_true = y_val\n",
        "        elif dataset == 'testing':\n",
        "          self.y_true = y_test\n",
        "        else: \n",
        "          raise Exception(f'Specify the dataset to be used for calculating the metrics. The string has to be either \"testing\", \"training\" or \"validation\", however it was {dataset}.')\n",
        "        \n",
        "        self.class_statistics = self.get_statistics(x_train, x_val, x_test, y_train, y_val, y_test)\n",
        "\n",
        "        self.training_dates = training_dates\n",
        "        self.validation_dates = validation_dates\n",
        "        self.testing_dates = testing_dates\n",
        "        self.tile_size = tile_size\n",
        "        self.step_size = step_size\n",
        "        self.run_count = run_count\n",
        "\n",
        "        self.jacard = self.jacard_coef(self.y_true, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "        self.conf_matrix_land = self.confusion_matrix(self.y_true, y_pred, 2)\n",
        "        self.conf_matrix_valid = self.confusion_matrix(self.y_true, y_pred, 1)\n",
        "        self.conf_matrix_invalid = self.confusion_matrix(self.y_true, y_pred, 0)\n",
        "\n",
        "        self.precision_land = self.precision(self.conf_matrix_land)\n",
        "        self.sensitivity_recall_land = self.sensitivity_recall(self.conf_matrix_land)\n",
        "        self.specificy_land = self.specificy(self.conf_matrix_land)\n",
        "\n",
        "        self.precision_valid = self.precision(self.conf_matrix_valid)\n",
        "        self.sensitivity_recall_valid = self.sensitivity_recall(self.conf_matrix_valid)\n",
        "        self.specificy_valid = self.specificy(self.conf_matrix_valid)\n",
        "\n",
        "        self.precision_invalid = self.precision(self.conf_matrix_invalid)\n",
        "        self.sensitivity_recall_invalid = self.sensitivity_recall(self.conf_matrix_invalid)\n",
        "        self.specificy_invalid = self.specificy(self.conf_matrix_invalid)\n",
        "\n",
        "        self.f1_land = self.f1_scores(self.conf_matrix_land)\n",
        "        self.f1_invalid = self.f1_scores(self.conf_matrix_invalid)\n",
        "        self.f1_valid = self.f1_scores(self.conf_matrix_valid)\n",
        "\n",
        "    def jacard_coef(self, y_true, y_pred):\n",
        "        y_true_f = keras.backend.flatten(y_true)\n",
        "        y_pred_f = keras.backend.flatten(y_pred)\n",
        "\n",
        "        intersection = keras.backend.sum(y_true_f * y_pred_f)\n",
        "        return (intersection + 1.0) / (\n",
        "                keras.backend.sum(y_true_f) + keras.backend.sum(y_pred_f) - intersection + 1.0\n",
        "        )  #todo reason for +1?\n",
        "\n",
        "    def jacard_rounding_issue(self, y_true, y_pred):\n",
        "        # revert one hot encoding => binary tensor [0, 0, 1] back to label [2] (3D array to 2D array)\n",
        "        label_map_true = np.argmax(y_true, axis=-1)\n",
        "        label_map_pred = np.argmax(y_pred, axis=-1)\n",
        "        # convert 2D array into 1D array\n",
        "        flatten_true = np.reshape(label_map_true, (-1,))\n",
        "        flatten_pred = np.reshape(label_map_pred, (-1,))\n",
        "        # one hot encoding\n",
        "        one_hot_true = np.eye(3)[flatten_true]\n",
        "        one_hot_pred = np.eye(3)[flatten_pred]\n",
        "        # calculate intersection (A geschnitten B)\n",
        "        intersection = np.sum(one_hot_true * one_hot_pred)\n",
        "        # calculate union (a u B, A vereint B)\n",
        "        union = len(one_hot_true) + len(one_hot_pred) - intersection\n",
        "        # return jacard coefficient\n",
        "        return (intersection + 1) / (union + 1)\n",
        "\n",
        "    def confusion_matrix(self, y_true, y_pred, label):\n",
        "        true_positives = 0\n",
        "        false_positives = 0\n",
        "        true_negatives = 0\n",
        "        false_negatives = 0\n",
        "\n",
        "        # revert one hot encoding => binary tensor [0, 0, 1] back to label [2] (3D array to 2D array)\n",
        "        label_map_true = np.argmax(y_true, axis=-1)\n",
        "        label_map_pred = np.argmax(y_pred, axis=-1)\n",
        "        # convert 2D array into 1D array\n",
        "        flatten_true = np.reshape(label_map_true, (-1,))\n",
        "        flatten_pred = np.reshape(label_map_pred, (-1,))\n",
        "\n",
        "        tp_mask = (flatten_true == flatten_pred) & (flatten_true == label)\n",
        "        true_positives = np.count_nonzero(tp_mask)\n",
        "\n",
        "        fn_mask = (flatten_true == label) & (flatten_pred != label)\n",
        "        false_negatives = np.count_nonzero(fn_mask)\n",
        "\n",
        "        fp_mask = (flatten_true != label) & (flatten_pred == label)\n",
        "        false_positives = np.count_nonzero(fp_mask)\n",
        "\n",
        "        tn_mask = (flatten_true != label) & (flatten_pred != label)\n",
        "        true_negatives = np.count_nonzero(tn_mask)\n",
        "\n",
        "        return {\n",
        "            'true_positives': true_positives,\n",
        "            'false_positives': false_positives,\n",
        "            'true_negatives': true_negatives,\n",
        "            'false_negatives': false_negatives\n",
        "        }\n",
        "\n",
        "    def precision(self, conf_matrix):\n",
        "        return conf_matrix['true_positives'] / (conf_matrix['true_positives'] + conf_matrix['false_positives'])\n",
        "\n",
        "    def sensitivity_recall(self, conf_matrix):\n",
        "        return conf_matrix['true_positives'] / (conf_matrix['true_positives'] + conf_matrix['false_negatives'])\n",
        "\n",
        "    def negative_predictive(self, conf_matrix):\n",
        "        return conf_matrix['true_negatives'] / (conf_matrix['true_negatives'] + conf_matrix['false_negatives'])\n",
        "\n",
        "    def specificy(self, conf_matrix):\n",
        "        return conf_matrix['true_negatives'] / (conf_matrix['true_negatives'] + conf_matrix['false_positives'])\n",
        "\n",
        "    def f1_scores(self, conf_matrix):\n",
        "        prec = self.precision(conf_matrix)\n",
        "        recall = self.sensitivity_recall(conf_matrix)\n",
        "        return 2 * prec * recall / (prec + recall)\n",
        "\n",
        "    def print_metrics(self):\n",
        "        print(f'jacard index: {self.jacard} \\n')\n",
        "\n",
        "        print(f'precision_land: {self.precision_land}')\n",
        "        print(f'precision_valid: {self.precision_valid}')\n",
        "        print(f'precision_invalid: {self.precision_invalid} \\n')\n",
        "\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_land}')\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_valid}')\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_invalid} \\n')\n",
        "\n",
        "        print(f'specificy_invalid_land: {self.specificy_land}')\n",
        "        print(f'specificy_invalid_valid: {self.specificy_valid}')\n",
        "        print(f'specificy_invalid_invalid: {self.specificy_invalid} \\n')\n",
        "\n",
        "        print(f'f1_land: {self.f1_land}')\n",
        "        print(f'f1_invalid: {self.f1_invalid}')\n",
        "        print(f'f1_valid: {self.f1_valid}')\n",
        "\n",
        "        print(f'Training dates: {self.training_dates}, validation dates: {self.validation_dates}, testing dates: {self.testing_dates}')\n",
        "        print(f'Number of run: {self.run_count}, tile_size: {self.tile_size}, step_size: {self.step_size}')\n",
        "\n",
        "    def save_to_file(self):\n",
        "        file_name = f'../metrics/{self.tile_size}_{self.step_size}_{self.run_count}.pkl'\n",
        "        with open(file_name, 'wb') as file:\n",
        "            pickle.dump(self, file)\n",
        "\n",
        "    def get_label_count(self, array):\n",
        "        revert_one_hot = np.argmax(array, (-1))\n",
        "        flatten = np.reshape(revert_one_hot, (-1))\n",
        "        unique_vals, counts = np.unique(flatten, return_counts=True)\n",
        "        label_count = {}\n",
        "        for val, count in zip(unique_vals, counts):\n",
        "            label_count[f'{val}'] = count\n",
        "        return label_count\n",
        "\n",
        "    def get_statistics(self, x_train, x_val, x_test, y_train, y_val, y_test):\n",
        "       return {'y_train': self.get_label_count(y_train),\n",
        "                 'y_val': self.get_label_count(y_val), 'y_test': self.get_label_count(y_test)}\n",
        "    # todo add pixel accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "r6um1iVpbpix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Loading + Preparing Data"
      ],
      "metadata": {
        "id": "TQiNFtcib6wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "osm1lHOLb-Is",
        "outputId": "478858db-0ef7-4f76-c5a5-d302c16ee8c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls\n",
        "%cd drive/MyDrive/MachineLearning/Geospatial_ML\n",
        "! ls"
      ],
      "metadata": {
        "id": "HV1KZvqMb_6S",
        "outputId": "ec0a61c8-130f-42a9-dd76-d24e542462b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "architecture.drawio  evaluation  notebooks     README.md\n",
            "Copy_of_unet.ipynb   models\t prepare_data  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    concatenate,\n",
        "    Conv2DTranspose,\n",
        "    Dropout,\n",
        "    UpSampling2D\n",
        ")\n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle"
      ],
      "metadata": {
        "id": "0FB7ZXQkcKB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"../data_colab/256_200\"\n",
        "\n",
        "y_train  = np.load(os.path.join(data_directory, '2022_06_20.npz'))['y_mask']\n",
        "x_train  = np.load(os.path.join(data_directory, '2022_06_20.npz'))['x_input']\n",
        "\n",
        "y_val = np.load(os.path.join(data_directory, '2022_07_10.npz'))['y_mask']\n",
        "x_val = np.load(os.path.join(data_directory, '2022_07_10.npz'))['x_input']\n",
        "\n",
        "y_test = np.load(os.path.join(data_directory, '2022_07_25.npz'))['y_mask']\n",
        "x_test = np.load(os.path.join(data_directory, '2022_07_25.npz'))['x_input']\n",
        "\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "\n",
        "print(y_val.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "print(y_test.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "id": "-6ErV4yBcLs6",
        "outputId": "7423536e-f1bb-4c6c-f5ea-d4900f52434f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1251, 256, 256)\n",
            "(1251, 256, 256, 5)\n",
            "(1323, 256, 256)\n",
            "(1323, 256, 256, 5)\n",
            "(1258, 256, 256)\n",
            "(1258, 256, 256, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizing(X, y):\n",
        "\n",
        "  print(y.shape)\n",
        "  y_one_hot =  np.array([tf.one_hot(item, depth=3).numpy() for item in y])\n",
        "  print(y_one_hot.shape)\n",
        "  X_normal = X/255\n",
        "  return X_normal, y_one_hot"
      ],
      "metadata": {
        "id": "crUpzYlEcgq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = normalizing(x_train, y_train)\n",
        "\n",
        "X_val, y_val = normalizing(x_val, y_val)\n",
        "\n",
        "x_test, y_test = normalizing(x_test, y_test)\n"
      ],
      "metadata": {
        "id": "c4Q8g6SOcla5",
        "outputId": "a4e254b8-5ec7-45b8-e086-3fe956b666f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1251, 256, 256)\n",
            "(1251, 256, 256, 3)\n",
            "(1323, 256, 256)\n",
            "(1323, 256, 256, 3)\n",
            "(1258, 256, 256)\n",
            "(1258, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Compiling the model"
      ],
      "metadata": {
        "id": "L87xH5zJcYO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_2d(input_shape, num_classes):\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Downsample layers\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # Upsample layers\n",
        "    up5 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(up5)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    # Output layer\n",
        "    output = Conv2D(num_classes, (1, 1), activation='softmax')(conv7)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=[inputs], outputs=[output])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cUPkEV0Ic2nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_2d(input_shape=(256, 256, 5), num_classes=3)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "t7j2vHOtc4my",
        "outputId": "f2549bd4-9a14-4cbf-9f9d-83b462b81ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)          [(None, 256, 256, 5  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_300 (Conv2D)            (None, 256, 256, 64  2944        ['input_21[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_301 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_300[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_60 (MaxPooling2D  (None, 128, 128, 64  0          ['conv2d_301[0][0]']             \n",
            " )                              )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_302 (Conv2D)            (None, 128, 128, 12  73856       ['max_pooling2d_60[0][0]']       \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_303 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_302[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_61 (MaxPooling2D  (None, 64, 64, 128)  0          ['conv2d_303[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_304 (Conv2D)            (None, 64, 64, 256)  295168      ['max_pooling2d_61[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_305 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_304[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_62 (MaxPooling2D  (None, 32, 32, 256)  0          ['conv2d_305[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv2d_306 (Conv2D)            (None, 32, 32, 512)  1180160     ['max_pooling2d_62[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_307 (Conv2D)            (None, 32, 32, 512)  2359808     ['conv2d_306[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_60 (UpSampling2D  (None, 64, 64, 512)  0          ['conv2d_307[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_60 (Concatenate)   (None, 64, 64, 768)  0           ['up_sampling2d_60[0][0]',       \n",
            "                                                                  'conv2d_305[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_308 (Conv2D)            (None, 64, 64, 256)  1769728     ['concatenate_60[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_309 (Conv2D)            (None, 64, 64, 256)  590080      ['conv2d_308[0][0]']             \n",
            "                                                                                                  \n",
            " up_sampling2d_61 (UpSampling2D  (None, 128, 128, 25  0          ['conv2d_309[0][0]']             \n",
            " )                              6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_61 (Concatenate)   (None, 128, 128, 38  0           ['up_sampling2d_61[0][0]',       \n",
            "                                4)                                'conv2d_303[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_310 (Conv2D)            (None, 128, 128, 12  442496      ['concatenate_61[0][0]']         \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_311 (Conv2D)            (None, 128, 128, 12  147584      ['conv2d_310[0][0]']             \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_62 (UpSampling2D  (None, 256, 256, 12  0          ['conv2d_311[0][0]']             \n",
            " )                              8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_62 (Concatenate)   (None, 256, 256, 19  0           ['up_sampling2d_62[0][0]',       \n",
            "                                2)                                'conv2d_301[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_312 (Conv2D)            (None, 256, 256, 64  110656      ['concatenate_62[0][0]']         \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_313 (Conv2D)            (None, 256, 256, 64  36928       ['conv2d_312[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_314 (Conv2D)            (None, 256, 256, 3)  195         ['conv2d_313[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,784,195\n",
            "Trainable params: 7,784,195\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Execute trainigs + saving results"
      ],
      "metadata": {
        "id": "R55UTUmGc73x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tile_size = 256\n",
        "step_size = 200\n",
        "saving_path = 'experiment_1'\n",
        "training_dates = '2022_06_20'\n",
        "validation_dates = '2022_07_10'\n",
        "testing_dates = '2022_07_25'"
      ],
      "metadata": {
        "id": "qHDLwE-AftkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_training(count):\n",
        "  print(f'Start training number {count}')\n",
        "  model = unet_2d(input_shape=(256, 256, 5), num_classes=3)\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=categorical_crossentropy,\n",
        "                metrics=['accuracy']) # are weights resetted?\n",
        "\n",
        "  early_stop = EarlyStopping(monitor='accuracy', patience=5) \n",
        "\n",
        "  model_history = model.fit(x=x_train, y=y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stop]) \n",
        "  print('training completed')\n",
        "  \n",
        "  # saving model\n",
        "  model_name = f'{tile_size}_{step_size}_run_{count}'\n",
        "  model.save(f'../models/{saving_path}/model_{model_name}.h5')\n",
        "  print('saving model completed')\n",
        "\n",
        "  # saving model history\n",
        "  with open(f'../models/{saving_path}/history_{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(model_history.history, file_pi)\n",
        "  print('saving history completed')\n",
        "\n",
        "  # making predictions\n",
        "  pred_test = model.predict(x_test)\n",
        "  pred_val = model.predict(x_val)\n",
        "  pred_train = model.predict(x_train)\n",
        "  print('making predictions completed')\n",
        "  print(pred_test.shape)\n",
        "  print(pred_val.shape)\n",
        "  print(pred_train.shape)\n",
        "\n",
        "  # calculating metrics\n",
        "  metrics_test = EvaluationMetrics(x_train, x_val, x_test, y_train, y_val, y_test, pred_test, training_dates, validation_dates, testing_dates, tile_size, step_size, count)\n",
        "  metrics_val = EvaluationMetrics(x_train, x_val, x_test, y_train, y_val, y_val, pred_val, training_dates, validation_dates, testing_dates, tile_size, step_size, count)\n",
        "  metrics_train = EvaluationMetrics(x_train, x_val, x_test, y_train, y_val, y_train, pred_train, training_dates, validation_dates, testing_dates, tile_size, step_size, count)\n",
        "  print('calculating metrics completed')\n",
        "\n",
        "  # saving metrics\n",
        "  with open(f'../metrics/{saving_path}/metrics_test{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(metrics_test, file_pi)\n",
        "  with open(f'../metrics/{saving_path}/metrics_val{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(metrics_val, file_pi)\n",
        "  with open(f'../metrics/{saving_path}/metrics_train{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(metrics_train, file_pi)\n",
        "  print('saving metrics completed')\n",
        "\n",
        "  return  {'metrics_test': metrics_test, 'metrics_val': metrics_val, 'metrics_train': metrics_train}"
      ],
      "metadata": {
        "id": "lYGEuLXWdKLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics_test = []\n",
        "all_metrics_val = []\n",
        "all_metrics_train = []\n",
        "\n",
        "\n",
        "for i in range(0,10):\n",
        "  metrics_dict = execute_training(i)\n",
        "  all_metrics_test.append(metrics_dict['metrics_test'])\n",
        "  all_metrics_val.append(metrics_dict['metrics_val'])\n",
        "  all_metrics_train.append(metrics_dict['metrics_train'])"
      ],
      "metadata": {
        "id": "ZD4NX8eCffFZ",
        "outputId": "1b9645c9-6512-4c0e-ecb5-3c9c5bf72e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training number 0\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - 19s 326ms/step - loss: 0.8118 - accuracy: 0.8085 - val_loss: 7.7246 - val_accuracy: 0.9497\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.1311 - accuracy: 0.9656 - val_loss: 7.4357 - val_accuracy: 0.9747\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0755 - accuracy: 0.9722 - val_loss: 9.0582 - val_accuracy: 0.9754\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0677 - accuracy: 0.9743 - val_loss: 15.0085 - val_accuracy: 0.9705\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0693 - accuracy: 0.9743 - val_loss: 7.2937 - val_accuracy: 0.9773\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0611 - accuracy: 0.9765 - val_loss: 8.5024 - val_accuracy: 0.9768\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0576 - accuracy: 0.9785 - val_loss: 4.7256 - val_accuracy: 0.9811\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0517 - accuracy: 0.9799 - val_loss: 3.6195 - val_accuracy: 0.9822\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0513 - accuracy: 0.9806 - val_loss: 6.7851 - val_accuracy: 0.9725\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.1012 - accuracy: 0.9663 - val_loss: 10.8483 - val_accuracy: 0.9758\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0625 - accuracy: 0.9773 - val_loss: 8.2651 - val_accuracy: 0.9795\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0529 - accuracy: 0.9799 - val_loss: 4.5081 - val_accuracy: 0.9813\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0496 - accuracy: 0.9809 - val_loss: 4.6358 - val_accuracy: 0.9821\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0508 - accuracy: 0.9808 - val_loss: 5.4666 - val_accuracy: 0.9839\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0448 - accuracy: 0.9830 - val_loss: 5.8204 - val_accuracy: 0.9841\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0438 - accuracy: 0.9832 - val_loss: 4.4061 - val_accuracy: 0.9849\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0416 - accuracy: 0.9840 - val_loss: 4.4020 - val_accuracy: 0.9836\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0413 - accuracy: 0.9843 - val_loss: 5.5211 - val_accuracy: 0.9854\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0414 - accuracy: 0.9839 - val_loss: 6.1923 - val_accuracy: 0.9842\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0388 - accuracy: 0.9853 - val_loss: 4.1767 - val_accuracy: 0.9845\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0364 - accuracy: 0.9855 - val_loss: 6.6996 - val_accuracy: 0.9833\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0392 - accuracy: 0.9846 - val_loss: 5.5539 - val_accuracy: 0.9758\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 5.5175 - val_accuracy: 0.9762\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0301 - accuracy: 0.9877 - val_loss: 4.0098 - val_accuracy: 0.9840\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0352 - accuracy: 0.9867 - val_loss: 4.4961 - val_accuracy: 0.9816\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0287 - accuracy: 0.9885 - val_loss: 5.4565 - val_accuracy: 0.9792\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0303 - accuracy: 0.9876 - val_loss: 3.7426 - val_accuracy: 0.9862\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0253 - accuracy: 0.9897 - val_loss: 4.9647 - val_accuracy: 0.9866\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0240 - accuracy: 0.9902 - val_loss: 4.4688 - val_accuracy: 0.9848\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0238 - accuracy: 0.9905 - val_loss: 5.3552 - val_accuracy: 0.9852\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0234 - accuracy: 0.9909 - val_loss: 4.0254 - val_accuracy: 0.9858\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0262 - accuracy: 0.9898 - val_loss: 3.7809 - val_accuracy: 0.9860\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0189 - accuracy: 0.9926 - val_loss: 28.7298 - val_accuracy: 0.9544\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0294 - accuracy: 0.9886 - val_loss: 10.7595 - val_accuracy: 0.9566\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0285 - accuracy: 0.9884 - val_loss: 4.4758 - val_accuracy: 0.9875\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 8.9363 - val_accuracy: 0.9764\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0169 - accuracy: 0.9932 - val_loss: 8.6931 - val_accuracy: 0.9829\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0136 - accuracy: 0.9948 - val_loss: 6.9378 - val_accuracy: 0.9862\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0121 - accuracy: 0.9955 - val_loss: 10.2253 - val_accuracy: 0.9835\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0102 - accuracy: 0.9962 - val_loss: 8.9487 - val_accuracy: 0.9848\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 9.8975 - val_accuracy: 0.9859\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 11.6162 - val_accuracy: 0.9820\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 13.3989 - val_accuracy: 0.9807\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 12.4354 - val_accuracy: 0.9858\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 14.4241 - val_accuracy: 0.9852\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 16.2457 - val_accuracy: 0.9852\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 19.0802 - val_accuracy: 0.9842\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 14.5943 - val_accuracy: 0.9856\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 15.3923 - val_accuracy: 0.9861\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 17.3858 - val_accuracy: 0.9857\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 18.0727 - val_accuracy: 0.9860\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 19.2802 - val_accuracy: 0.9866\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 21.5403 - val_accuracy: 0.9857\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 22.1385 - val_accuracy: 0.9859\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 22.5783 - val_accuracy: 0.9865\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 23.4052 - val_accuracy: 0.9859\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 23.2513 - val_accuracy: 0.9865\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 23.5829 - val_accuracy: 0.9860\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 24.1259 - val_accuracy: 0.9857\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 23.9196 - val_accuracy: 0.9854\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 25.2019 - val_accuracy: 0.9860\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 24.6465 - val_accuracy: 0.9859\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 25.7010 - val_accuracy: 0.9855\n",
            "Epoch 64/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 25.8503 - val_accuracy: 0.9862\n",
            "Epoch 65/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 26.5508 - val_accuracy: 0.9865\n",
            "Epoch 66/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 26.3912 - val_accuracy: 0.9865\n",
            "Epoch 67/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 27.3857 - val_accuracy: 0.9856\n",
            "Epoch 68/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 27.9820 - val_accuracy: 0.9859\n",
            "Epoch 69/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 29.7667 - val_accuracy: 0.9856\n",
            "Epoch 70/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 27.8074 - val_accuracy: 0.9861\n",
            "Epoch 71/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 29.4191 - val_accuracy: 0.9853\n",
            "Epoch 72/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 28.2864 - val_accuracy: 0.9865\n",
            "Epoch 73/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 9.8618e-04 - accuracy: 0.9997 - val_loss: 29.1439 - val_accuracy: 0.9863\n",
            "Epoch 74/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 31.4325 - val_accuracy: 0.9850\n",
            "Epoch 75/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 25.7926 - val_accuracy: 0.9840\n",
            "Epoch 76/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 19.7970 - val_accuracy: 0.9870\n",
            "Epoch 77/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 24.7794 - val_accuracy: 0.9859\n",
            "Epoch 78/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 26.8414 - val_accuracy: 0.9849\n",
            "training completed\n",
            "saving model completed\n",
            "saving history completed\n",
            "40/40 [==============================] - 2s 58ms/step\n",
            "42/42 [==============================] - 2s 58ms/step\n",
            "40/40 [==============================] - 2s 58ms/step\n",
            "making predictions completed\n",
            "(1258, 256, 256, 3)\n",
            "(1323, 256, 256, 3)\n",
            "(1251, 256, 256, 3)\n",
            "calculating metrics completed\n",
            "saving metrics completed\n",
            "Start training number 1\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - 17s 320ms/step - loss: 0.3753 - accuracy: 0.8334 - val_loss: 18.7069 - val_accuracy: 0.9632\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.1253 - accuracy: 0.9609 - val_loss: 20.2988 - val_accuracy: 0.9662\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0832 - accuracy: 0.9712 - val_loss: 7.6633 - val_accuracy: 0.9758\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0700 - accuracy: 0.9736 - val_loss: 5.3358 - val_accuracy: 0.9770\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0624 - accuracy: 0.9765 - val_loss: 5.5490 - val_accuracy: 0.9806\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0584 - accuracy: 0.9778 - val_loss: 6.5850 - val_accuracy: 0.9796\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0581 - accuracy: 0.9784 - val_loss: 5.6183 - val_accuracy: 0.9811\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0516 - accuracy: 0.9800 - val_loss: 4.5948 - val_accuracy: 0.9833\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0532 - accuracy: 0.9797 - val_loss: 5.9318 - val_accuracy: 0.9659\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0545 - accuracy: 0.9795 - val_loss: 6.1536 - val_accuracy: 0.9807\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0480 - accuracy: 0.9817 - val_loss: 3.6073 - val_accuracy: 0.9844\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0524 - accuracy: 0.9808 - val_loss: 5.6979 - val_accuracy: 0.9791\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0492 - accuracy: 0.9813 - val_loss: 4.4009 - val_accuracy: 0.9845\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0481 - accuracy: 0.9818 - val_loss: 4.5941 - val_accuracy: 0.9830\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0431 - accuracy: 0.9836 - val_loss: 4.8048 - val_accuracy: 0.9795\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0448 - accuracy: 0.9829 - val_loss: 3.2546 - val_accuracy: 0.9855\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0415 - accuracy: 0.9840 - val_loss: 4.4687 - val_accuracy: 0.9856\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0402 - accuracy: 0.9847 - val_loss: 4.5131 - val_accuracy: 0.9857\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0384 - accuracy: 0.9855 - val_loss: 5.0657 - val_accuracy: 0.9849\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0747 - accuracy: 0.9750 - val_loss: 3.5869 - val_accuracy: 0.9795\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.1511 - accuracy: 0.9536 - val_loss: 334.1225 - val_accuracy: 0.7305\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.3498 - accuracy: 0.8845 - val_loss: 42.0367 - val_accuracy: 0.9549\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.1116 - accuracy: 0.9668 - val_loss: 8.4785 - val_accuracy: 0.9758\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0715 - accuracy: 0.9745 - val_loss: 4.1623 - val_accuracy: 0.9780\n",
            "training completed\n",
            "saving model completed\n",
            "saving history completed\n",
            "40/40 [==============================] - 2s 57ms/step\n",
            "42/42 [==============================] - 2s 57ms/step\n",
            "40/40 [==============================] - 2s 57ms/step\n",
            "making predictions completed\n",
            "(1258, 256, 256, 3)\n",
            "(1323, 256, 256, 3)\n",
            "(1251, 256, 256, 3)\n",
            "calculating metrics completed\n",
            "saving metrics completed\n",
            "Start training number 2\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - 17s 316ms/step - loss: 0.4629 - accuracy: 0.8285 - val_loss: 41.1847 - val_accuracy: 0.9639\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.1008 - accuracy: 0.9679 - val_loss: 12.3812 - val_accuracy: 0.9705\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0752 - accuracy: 0.9728 - val_loss: 6.8101 - val_accuracy: 0.9772\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0660 - accuracy: 0.9757 - val_loss: 7.6813 - val_accuracy: 0.9766\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0601 - accuracy: 0.9775 - val_loss: 11.1403 - val_accuracy: 0.9750\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0554 - accuracy: 0.9794 - val_loss: 6.8494 - val_accuracy: 0.9788\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0601 - accuracy: 0.9782 - val_loss: 6.2070 - val_accuracy: 0.9799\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0522 - accuracy: 0.9804 - val_loss: 4.1822 - val_accuracy: 0.9819\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0533 - accuracy: 0.9804 - val_loss: 3.4231 - val_accuracy: 0.9825\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0494 - accuracy: 0.9811 - val_loss: 4.0593 - val_accuracy: 0.9837\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0450 - accuracy: 0.9827 - val_loss: 5.6854 - val_accuracy: 0.9842\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0455 - accuracy: 0.9829 - val_loss: 5.1702 - val_accuracy: 0.9823\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0447 - accuracy: 0.9830 - val_loss: 3.4439 - val_accuracy: 0.9850\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0426 - accuracy: 0.9841 - val_loss: 3.2313 - val_accuracy: 0.9838\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0436 - accuracy: 0.9835 - val_loss: 3.2380 - val_accuracy: 0.9849\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0409 - accuracy: 0.9843 - val_loss: 4.1230 - val_accuracy: 0.9795\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0416 - accuracy: 0.9845 - val_loss: 4.5888 - val_accuracy: 0.9840\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0481 - accuracy: 0.9834 - val_loss: 124.5551 - val_accuracy: 0.7090\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.1043 - accuracy: 0.9663 - val_loss: 7.2352 - val_accuracy: 0.9789\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0532 - accuracy: 0.9803 - val_loss: 5.6636 - val_accuracy: 0.9821\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0488 - accuracy: 0.9816 - val_loss: 4.0968 - val_accuracy: 0.9836\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0440 - accuracy: 0.9838 - val_loss: 3.0479 - val_accuracy: 0.9843\n",
            "training completed\n",
            "saving model completed\n",
            "saving history completed\n",
            "40/40 [==============================] - 2s 57ms/step\n",
            "42/42 [==============================] - 2s 58ms/step\n",
            "40/40 [==============================] - 2s 58ms/step\n",
            "making predictions completed\n",
            "(1258, 256, 256, 3)\n",
            "(1323, 256, 256, 3)\n",
            "(1251, 256, 256, 3)\n",
            "calculating metrics completed\n",
            "saving metrics completed\n",
            "Start training number 3\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - 17s 311ms/step - loss: 0.6339 - accuracy: 0.7433 - val_loss: 186.3434 - val_accuracy: 0.7345\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.1721 - accuracy: 0.9518 - val_loss: 16.2854 - val_accuracy: 0.9704\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0852 - accuracy: 0.9714 - val_loss: 7.4612 - val_accuracy: 0.9736\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0741 - accuracy: 0.9730 - val_loss: 8.9096 - val_accuracy: 0.9742\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0664 - accuracy: 0.9750 - val_loss: 8.2113 - val_accuracy: 0.9753\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0606 - accuracy: 0.9769 - val_loss: 7.5295 - val_accuracy: 0.9757\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0593 - accuracy: 0.9776 - val_loss: 5.1619 - val_accuracy: 0.9781\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0556 - accuracy: 0.9794 - val_loss: 5.1665 - val_accuracy: 0.9803\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0526 - accuracy: 0.9801 - val_loss: 6.1950 - val_accuracy: 0.9756\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0534 - accuracy: 0.9798 - val_loss: 4.2393 - val_accuracy: 0.9807\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0469 - accuracy: 0.9819 - val_loss: 4.1770 - val_accuracy: 0.9833\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0465 - accuracy: 0.9825 - val_loss: 4.0024 - val_accuracy: 0.9837\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0427 - accuracy: 0.9834 - val_loss: 4.4081 - val_accuracy: 0.9843\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0392 - accuracy: 0.9852 - val_loss: 12.2407 - val_accuracy: 0.9646\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0427 - accuracy: 0.9835 - val_loss: 5.3091 - val_accuracy: 0.9737\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0426 - accuracy: 0.9837 - val_loss: 2.9126 - val_accuracy: 0.9819\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0408 - accuracy: 0.9844 - val_loss: 4.1210 - val_accuracy: 0.9853\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0379 - accuracy: 0.9859 - val_loss: 2.9874 - val_accuracy: 0.9842\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0373 - accuracy: 0.9859 - val_loss: 3.7400 - val_accuracy: 0.9847\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0337 - accuracy: 0.9874 - val_loss: 5.7053 - val_accuracy: 0.9802\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0323 - accuracy: 0.9879 - val_loss: 4.9751 - val_accuracy: 0.9869\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0331 - accuracy: 0.9882 - val_loss: 5.2111 - val_accuracy: 0.9864\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0317 - accuracy: 0.9884 - val_loss: 4.2065 - val_accuracy: 0.9856\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0297 - accuracy: 0.9892 - val_loss: 5.7992 - val_accuracy: 0.9727\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0347 - accuracy: 0.9868 - val_loss: 6.4637 - val_accuracy: 0.9740\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0315 - accuracy: 0.9883 - val_loss: 4.3266 - val_accuracy: 0.9808\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0274 - accuracy: 0.9900 - val_loss: 3.4711 - val_accuracy: 0.9866\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 3.8293 - val_accuracy: 0.9880\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0240 - accuracy: 0.9911 - val_loss: 2.6929 - val_accuracy: 0.9870\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0200 - accuracy: 0.9926 - val_loss: 3.8628 - val_accuracy: 0.9868\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0240 - accuracy: 0.9912 - val_loss: 7.6404 - val_accuracy: 0.9774\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 5.6489 - val_accuracy: 0.9835\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 4.2255 - val_accuracy: 0.9852\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0199 - accuracy: 0.9930 - val_loss: 7.2347 - val_accuracy: 0.9812\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 11.2490 - val_accuracy: 0.9755\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 8.7978 - val_accuracy: 0.9781\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 1.2381 - accuracy: 0.8053 - val_loss: 18.7633 - val_accuracy: 0.9641\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.1116 - accuracy: 0.9668 - val_loss: 13.1279 - val_accuracy: 0.9738\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0874 - accuracy: 0.9719 - val_loss: 13.3515 - val_accuracy: 0.9747\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0727 - accuracy: 0.9743 - val_loss: 7.9841 - val_accuracy: 0.9760\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0670 - accuracy: 0.9752 - val_loss: 8.8052 - val_accuracy: 0.9763\n",
            "training completed\n",
            "saving model completed\n",
            "saving history completed\n",
            "40/40 [==============================] - 2s 57ms/step\n",
            "42/42 [==============================] - 2s 58ms/step\n",
            "40/40 [==============================] - 2s 58ms/step\n",
            "making predictions completed\n",
            "(1258, 256, 256, 3)\n",
            "(1323, 256, 256, 3)\n",
            "(1251, 256, 256, 3)\n",
            "calculating metrics completed\n",
            "saving metrics completed\n",
            "Start training number 4\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - 18s 312ms/step - loss: 0.5902 - accuracy: 0.7753 - val_loss: 40.1679 - val_accuracy: 0.7254\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.1572 - accuracy: 0.9507 - val_loss: 15.6859 - val_accuracy: 0.9699\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0894 - accuracy: 0.9707 - val_loss: 9.5666 - val_accuracy: 0.9738\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0753 - accuracy: 0.9729 - val_loss: 8.2772 - val_accuracy: 0.9752\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0646 - accuracy: 0.9761 - val_loss: 13.3450 - val_accuracy: 0.9774\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0637 - accuracy: 0.9772 - val_loss: 7.7721 - val_accuracy: 0.9792\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0565 - accuracy: 0.9790 - val_loss: 8.1326 - val_accuracy: 0.9794\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0554 - accuracy: 0.9795 - val_loss: 6.3768 - val_accuracy: 0.9809\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0504 - accuracy: 0.9808 - val_loss: 7.5102 - val_accuracy: 0.9820\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0468 - accuracy: 0.9822 - val_loss: 6.4664 - val_accuracy: 0.9830\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0462 - accuracy: 0.9823 - val_loss: 5.6865 - val_accuracy: 0.9841\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0501 - accuracy: 0.9811 - val_loss: 7.8813 - val_accuracy: 0.9747\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0479 - accuracy: 0.9819 - val_loss: 4.7734 - val_accuracy: 0.9845\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0453 - accuracy: 0.9828 - val_loss: 7.6094 - val_accuracy: 0.9631\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0533 - accuracy: 0.9802 - val_loss: 5.1802 - val_accuracy: 0.9821\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0445 - accuracy: 0.9832 - val_loss: 2.9181 - val_accuracy: 0.9854\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0408 - accuracy: 0.9843 - val_loss: 3.5770 - val_accuracy: 0.9834\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0459 - accuracy: 0.9824 - val_loss: 2.5802 - val_accuracy: 0.9844\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0416 - accuracy: 0.9837 - val_loss: 3.2434 - val_accuracy: 0.9851\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0375 - accuracy: 0.9855 - val_loss: 3.6829 - val_accuracy: 0.9858\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 2.2233 - val_accuracy: 0.9858\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0343 - accuracy: 0.9863 - val_loss: 3.2556 - val_accuracy: 0.9839\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0320 - accuracy: 0.9872 - val_loss: 2.3891 - val_accuracy: 0.9839\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0315 - accuracy: 0.9873 - val_loss: 2.8902 - val_accuracy: 0.9875\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0329 - accuracy: 0.9868 - val_loss: 4.4268 - val_accuracy: 0.9862\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0335 - accuracy: 0.9863 - val_loss: 4.1280 - val_accuracy: 0.9706\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0260 - accuracy: 0.9892 - val_loss: 5.0029 - val_accuracy: 0.9749\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0264 - accuracy: 0.9892 - val_loss: 4.9015 - val_accuracy: 0.9747\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0229 - accuracy: 0.9908 - val_loss: 4.9507 - val_accuracy: 0.9735\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0229 - accuracy: 0.9907 - val_loss: 6.3853 - val_accuracy: 0.9735\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0222 - accuracy: 0.9912 - val_loss: 3.2406 - val_accuracy: 0.9863\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 7.3022 - val_accuracy: 0.9695\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0201 - accuracy: 0.9922 - val_loss: 5.4401 - val_accuracy: 0.9764\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0222 - accuracy: 0.9912 - val_loss: 4.7574 - val_accuracy: 0.9754\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0198 - accuracy: 0.9923 - val_loss: 3.8777 - val_accuracy: 0.9811\n",
            "Epoch 36/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0166 - accuracy: 0.9935 - val_loss: 5.6064 - val_accuracy: 0.9803\n",
            "Epoch 37/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0140 - accuracy: 0.9947 - val_loss: 4.7311 - val_accuracy: 0.9843\n",
            "Epoch 38/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 15.9768 - val_accuracy: 0.9595\n",
            "Epoch 39/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0171 - accuracy: 0.9934 - val_loss: 7.5635 - val_accuracy: 0.9670\n",
            "Epoch 40/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0125 - accuracy: 0.9953 - val_loss: 4.8422 - val_accuracy: 0.9814\n",
            "Epoch 41/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 8.8456 - val_accuracy: 0.9793\n",
            "Epoch 42/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 8.1924 - val_accuracy: 0.9791\n",
            "Epoch 43/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 11.3045 - val_accuracy: 0.9768\n",
            "Epoch 44/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 12.9119 - val_accuracy: 0.9746\n",
            "Epoch 45/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 11.2263 - val_accuracy: 0.9789\n",
            "Epoch 46/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 11.1190 - val_accuracy: 0.9787\n",
            "Epoch 47/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 10.4078 - val_accuracy: 0.9804\n",
            "Epoch 48/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 12.3490 - val_accuracy: 0.9790\n",
            "Epoch 49/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 12.9380 - val_accuracy: 0.9785\n",
            "Epoch 50/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 13.0111 - val_accuracy: 0.9778\n",
            "Epoch 51/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 14.7392 - val_accuracy: 0.9785\n",
            "Epoch 52/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 16.0170 - val_accuracy: 0.9786\n",
            "Epoch 53/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 13.9206 - val_accuracy: 0.9822\n",
            "Epoch 54/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 18.2613 - val_accuracy: 0.9776\n",
            "Epoch 55/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 15.0148 - val_accuracy: 0.9821\n",
            "Epoch 56/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 17.0390 - val_accuracy: 0.9811\n",
            "Epoch 57/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 17.5543 - val_accuracy: 0.9813\n",
            "Epoch 58/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 18.2563 - val_accuracy: 0.9817\n",
            "Epoch 59/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 15.0649 - val_accuracy: 0.9826\n",
            "Epoch 60/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 17.2713 - val_accuracy: 0.9819\n",
            "Epoch 61/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 13.7455 - val_accuracy: 0.9830\n",
            "Epoch 62/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 8.5668 - val_accuracy: 0.9806\n",
            "Epoch 63/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 9.4073 - val_accuracy: 0.9808\n",
            "training completed\n",
            "saving model completed\n",
            "saving history completed\n",
            "40/40 [==============================] - 2s 58ms/step\n",
            "42/42 [==============================] - 2s 57ms/step\n",
            "40/40 [==============================] - 2s 57ms/step\n",
            "making predictions completed\n",
            "(1258, 256, 256, 3)\n",
            "(1323, 256, 256, 3)\n",
            "(1251, 256, 256, 3)\n",
            "calculating metrics completed\n",
            "saving metrics completed\n",
            "Start training number 5\n",
            "Epoch 1/100\n",
            "40/40 [==============================] - 17s 312ms/step - loss: 0.4152 - accuracy: 0.8307 - val_loss: 72.4946 - val_accuracy: 0.6909\n",
            "Epoch 2/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.1757 - accuracy: 0.9476 - val_loss: 20.8599 - val_accuracy: 0.9668\n",
            "Epoch 3/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0819 - accuracy: 0.9728 - val_loss: 16.3245 - val_accuracy: 0.9675\n",
            "Epoch 4/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0739 - accuracy: 0.9737 - val_loss: 5.2707 - val_accuracy: 0.9779\n",
            "Epoch 5/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0636 - accuracy: 0.9765 - val_loss: 10.5091 - val_accuracy: 0.9762\n",
            "Epoch 6/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0614 - accuracy: 0.9775 - val_loss: 8.5173 - val_accuracy: 0.9769\n",
            "Epoch 7/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0539 - accuracy: 0.9797 - val_loss: 4.9713 - val_accuracy: 0.9818\n",
            "Epoch 8/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0499 - accuracy: 0.9812 - val_loss: 4.4015 - val_accuracy: 0.9830\n",
            "Epoch 9/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0490 - accuracy: 0.9812 - val_loss: 4.7567 - val_accuracy: 0.9799\n",
            "Epoch 10/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 4.3743 - val_accuracy: 0.9837\n",
            "Epoch 11/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0441 - accuracy: 0.9829 - val_loss: 5.6086 - val_accuracy: 0.9822\n",
            "Epoch 12/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0412 - accuracy: 0.9845 - val_loss: 3.6071 - val_accuracy: 0.9840\n",
            "Epoch 13/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0462 - accuracy: 0.9827 - val_loss: 6.1992 - val_accuracy: 0.9828\n",
            "Epoch 14/100\n",
            "40/40 [==============================] - 10s 241ms/step - loss: 0.0421 - accuracy: 0.9842 - val_loss: 3.7567 - val_accuracy: 0.9837\n",
            "Epoch 15/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0403 - accuracy: 0.9847 - val_loss: 3.5184 - val_accuracy: 0.9847\n",
            "Epoch 16/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0388 - accuracy: 0.9852 - val_loss: 3.9899 - val_accuracy: 0.9865\n",
            "Epoch 17/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0353 - accuracy: 0.9862 - val_loss: 3.5392 - val_accuracy: 0.9858\n",
            "Epoch 18/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0349 - accuracy: 0.9865 - val_loss: 9.5418 - val_accuracy: 0.9717\n",
            "Epoch 19/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0329 - accuracy: 0.9873 - val_loss: 5.8590 - val_accuracy: 0.9844\n",
            "Epoch 20/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0346 - accuracy: 0.9863 - val_loss: 3.4875 - val_accuracy: 0.9858\n",
            "Epoch 21/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0268 - accuracy: 0.9891 - val_loss: 3.2888 - val_accuracy: 0.9873\n",
            "Epoch 22/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0245 - accuracy: 0.9902 - val_loss: 4.2978 - val_accuracy: 0.9880\n",
            "Epoch 23/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0251 - accuracy: 0.9904 - val_loss: 3.9146 - val_accuracy: 0.9857\n",
            "Epoch 24/100\n",
            "40/40 [==============================] - 10s 243ms/step - loss: 0.0207 - accuracy: 0.9918 - val_loss: 8.6810 - val_accuracy: 0.9769\n",
            "Epoch 25/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0229 - accuracy: 0.9910 - val_loss: 3.5325 - val_accuracy: 0.9875\n",
            "Epoch 26/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0190 - accuracy: 0.9927 - val_loss: 6.4497 - val_accuracy: 0.9838\n",
            "Epoch 27/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0160 - accuracy: 0.9939 - val_loss: 4.3039 - val_accuracy: 0.9870\n",
            "Epoch 28/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0163 - accuracy: 0.9937 - val_loss: 5.4960 - val_accuracy: 0.9874\n",
            "Epoch 29/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0133 - accuracy: 0.9951 - val_loss: 6.4366 - val_accuracy: 0.9852\n",
            "Epoch 30/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 6.0748 - val_accuracy: 0.9883\n",
            "Epoch 31/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 7.1595 - val_accuracy: 0.9765\n",
            "Epoch 32/100\n",
            "40/40 [==============================] - 10s 244ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 6.3489 - val_accuracy: 0.9883\n",
            "Epoch 33/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 7.5343 - val_accuracy: 0.9863\n",
            "Epoch 34/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0076 - accuracy: 0.9972 - val_loss: 10.4309 - val_accuracy: 0.9856\n",
            "Epoch 35/100\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.0083 - accuracy: 0.9970 - val_loss: 9.2114 - val_accuracy: 0.9879\n",
            "Epoch 36/100\n",
            "38/40 [===========================>..] - ETA: 0s - loss: 0.0067 - accuracy: 0.9976"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-7dd98bcaf469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmetrics_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mall_metrics_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mall_metrics_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics_val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-5941cd64bfce>\u001b[0m in \u001b[0;36mexecute_training\u001b[0;34m(count)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mearly_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training completed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Results"
      ],
      "metadata": {
        "id": "sv7CUFfxhFwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, metric in enumerate(all_metrics_test):\n",
        "  print(f'========= RUN {idx + 1} ============')\n",
        "  print(f'TEST DATA')\n",
        "  metric.print_metrics()\n",
        "  print()\n",
        "  print(f'VALIDATION DATA')\n",
        "  all_metrics_val[idx].print_metrics()\n",
        "  print(f'TRAINING DATA')\n",
        "  all_metrics_train[idx].print_metrics()\n",
        "  print()\n",
        "  print()\n",
        "\n"
      ],
      "metadata": {
        "id": "M6ctr30RqqGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_jacard(all_metrics):\n",
        "  jacard_array = []\n",
        "  for idx, metric in enumerate(all_metrics):\n",
        "    print(metric.jacard)\n",
        "    jacard_array.append(metric.jacard)\n",
        "\n",
        "  print()\n",
        "  print(f'Mean jacard index: {sum(jacard_array)/10}')\n",
        "  print()\n",
        "  print(f'Worst index: {min(jacard_array)}')\n",
        "  print(f'Best index: {max(jacard_array)}')\n",
        "  print(f'Variance: {max(jacard_array)-min(jacard_array)}')\n",
        "\n",
        "print('============ TEST DATA ===================')\n",
        "get_mean_jacard(all_metrics_test)\n",
        "print()\n",
        "\n",
        "print('============ VALIDATION DATA ===================')\n",
        "get_mean_jacard(all_metrics_val)\n",
        "print()\n",
        "\n",
        "print('============ TRAINING DATA ===================')\n",
        "get_mean_jacard(all_metrics_train)\n",
        "print()"
      ],
      "metadata": {
        "id": "R5extGwztwz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "execution time: ~ 70 min\n",
        "\n",
        "tf.Tensor(0.9303678, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9597043, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9749496, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9310194, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9781205, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9540997, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9542077, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.95823056, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9830309, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9656351, shape=(), dtype=float32)\n",
        "\n",
        "\n",
        "Mean jacard index: 0.9589365720748901\n",
        "\n",
        "\n",
        "Worst index: 0.9303678274154663\n",
        "\n",
        "Best index: 0.9830309152603149\n",
        "\n",
        "Variance: 0.05266308784484863\n",
        "\n",
        "\n",
        "start: 17:14\n"
      ],
      "metadata": {
        "id": "88QSlQGZhKLb"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}