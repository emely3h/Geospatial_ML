{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "flagged_img = np.asarray(Image.open(\"../data/flags_applied/2021_10_03/wq.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9410, 27602)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flagged_img.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to train the Unet model.\n",
    "\n",
    "Testing Image = \"unflagged\"\n",
    "\n",
    "Testing Label = \"flagged\"\n",
    "\n",
    "#Categories and pixel value\n",
    "\n",
    "Land=0\n",
    "\n",
    "invalid=253 - 255\n",
    "\n",
    "valid=others\n",
    "\n",
    "We are going to classify pixels into valid and invalid.\n",
    "Masks provides the value 0 to 255(which means RGB has already converted into 2D_label).\n",
    "You can check these labels' value like this.\n",
    "\n",
    "e.g.,\n",
    "```python\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "flagged_img = np.asarray(Image.open('../data/flags_applied/2021_10_03/wq.tif'))\n",
    "labels = np.expand_dims(flagged_img, axis=0)\n",
    "np.unique(labels)\n",
    "```\n",
    "\n",
    "On the other hand, input RGB images provide three values(each has 0 to 255 value).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert 256 (integral encoded) label into 2 labels(valid or invalid). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary_label(label):\n",
    "    if label == 0 or label >= 253:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 933120000\n",
    "flagged_img = np.asarray(Image.open(\"../data/flags_applied/2021_10_03/wq.tif\"))\n",
    "labels = np.expand_dims(flagged_img, axis=0)\n",
    "# apply binary label function to each pixel\n",
    "v_binary_label = np.vectorize(convert_to_binary_label)\n",
    "labels = v_binary_label(labels)\n",
    "# check unique labels (should be 0 and 1)\n",
    "np.unique(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Change the binary integral encode into [one-hot](https://en.wikipedia.org/wiki/One-hot) encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-03 16:22:44.424467: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "labels_cat = to_categorical(labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 9410, 27602, 2)\n"
     ]
    }
   ],
   "source": [
    "print(labels_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geospatial_ML-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
