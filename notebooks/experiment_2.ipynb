{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# U-Net Experiment 2: Exploring benefit of tile-overlapping"
      ],
      "metadata": {
        "collapsed": false,
        "id": "lf2uPiSlwKlg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Helper Classes"
      ],
      "metadata": {
        "id": "rJznpxWwbvFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "\n",
        "\n",
        "class EvaluationMetrics:\n",
        "    \"\"\"\n",
        "        This class calculates and summarizes evaluation metrics based on the predicted and true labels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x_train, x_val, x_test, y_train, y_val, y_test, y_pred, training_dates, validation_dates, testing_dates, tile_size, step_size,\n",
        "                 run_count):\n",
        "        self.class_statistics = self.get_statistics(x_train, x_val, x_test, y_train, y_val, y_test)\n",
        "\n",
        "        self.training_dates = training_dates\n",
        "        self.validation_dates = validation_dates\n",
        "        self.testing_dates = testing_dates\n",
        "        self.tile_size = tile_size\n",
        "        self.step_size = step_size\n",
        "        self.run_count = run_count\n",
        "\n",
        "        self.jacard = self.jacard_coef(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "        self.conf_matrix_land = self.confusion_matrix(y_test, y_pred, 2)\n",
        "        self.conf_matrix_valid = self.confusion_matrix(y_test, y_pred, 1)\n",
        "        self.conf_matrix_invalid = self.confusion_matrix(y_test, y_pred, 0)\n",
        "\n",
        "        self.precision_land = self.precision(self.conf_matrix_land)\n",
        "        self.sensitivity_recall_land = self.sensitivity_recall(self.conf_matrix_land)\n",
        "        self.specificy_land = self.specificy(self.conf_matrix_land)\n",
        "\n",
        "        self.precision_valid = self.precision(self.conf_matrix_valid)\n",
        "        self.sensitivity_recall_valid = self.sensitivity_recall(self.conf_matrix_valid)\n",
        "        self.specificy_valid = self.specificy(self.conf_matrix_valid)\n",
        "\n",
        "        self.precision_invalid = self.precision(self.conf_matrix_invalid)\n",
        "        self.sensitivity_recall_invalid = self.sensitivity_recall(self.conf_matrix_invalid)\n",
        "        self.specificy_invalid = self.specificy(self.conf_matrix_invalid)\n",
        "\n",
        "        self.f1_land = self.f1_scores(self.conf_matrix_land)\n",
        "        self.f1_invalid = self.f1_scores(self.conf_matrix_invalid)\n",
        "        self.f1_valid = self.f1_scores(self.conf_matrix_valid)\n",
        "\n",
        "    def jacard_coef(self, y_true, y_pred):\n",
        "        y_true_f = keras.backend.flatten(y_true)\n",
        "        y_pred_f = keras.backend.flatten(y_pred)\n",
        "\n",
        "        intersection = keras.backend.sum(y_true_f * y_pred_f)\n",
        "        return (intersection + 1.0) / (\n",
        "                keras.backend.sum(y_true_f) + keras.backend.sum(y_pred_f) - intersection + 1.0\n",
        "        )  #todo reason for +1?\n",
        "\n",
        "    def jacard_rounding_issue(self, y_true, y_pred):\n",
        "        # revert one hot encoding => binary tensor [0, 0, 1] back to label [2] (3D array to 2D array)\n",
        "        label_map_true = np.argmax(y_true, axis=-1)\n",
        "        label_map_pred = np.argmax(y_pred, axis=-1)\n",
        "        # convert 2D array into 1D array\n",
        "        flatten_true = np.reshape(label_map_true, (-1,))\n",
        "        flatten_pred = np.reshape(label_map_pred, (-1,))\n",
        "        # one hot encoding\n",
        "        one_hot_true = np.eye(3)[flatten_true]\n",
        "        one_hot_pred = np.eye(3)[flatten_pred]\n",
        "        # calculate intersection (A geschnitten B)\n",
        "        intersection = np.sum(one_hot_true * one_hot_pred)\n",
        "        # calculate union (a u B, A vereint B)\n",
        "        union = len(one_hot_true) + len(one_hot_pred) - intersection\n",
        "        # return jacard coefficient\n",
        "        return (intersection + 1) / (union + 1)\n",
        "\n",
        "    def confusion_matrix(self, y_true, y_pred, label):\n",
        "        true_positives = 0\n",
        "        false_positives = 0\n",
        "        true_negatives = 0\n",
        "        false_negatives = 0\n",
        "\n",
        "        # revert one hot encoding => binary tensor [0, 0, 1] back to label [2] (3D array to 2D array)\n",
        "        label_map_true = np.argmax(y_true, axis=-1)\n",
        "        label_map_pred = np.argmax(y_pred, axis=-1)\n",
        "        # convert 2D array into 1D array\n",
        "        flatten_true = np.reshape(label_map_true, (-1,))\n",
        "        flatten_pred = np.reshape(label_map_pred, (-1,))\n",
        "\n",
        "        tp_mask = (flatten_true == flatten_pred) & (flatten_true == label)\n",
        "        true_positives = np.count_nonzero(tp_mask)\n",
        "\n",
        "        fn_mask = (flatten_true == label) & (flatten_pred != label)\n",
        "        false_negatives = np.count_nonzero(fn_mask)\n",
        "\n",
        "        fp_mask = (flatten_true != label) & (flatten_pred == label)\n",
        "        false_positives = np.count_nonzero(fp_mask)\n",
        "\n",
        "        tn_mask = (flatten_true != label) & (flatten_pred != label)\n",
        "        true_negatives = np.count_nonzero(tn_mask)\n",
        "\n",
        "        return {\n",
        "            'true_positives': true_positives,\n",
        "            'false_positives': false_positives,\n",
        "            'true_negatives': true_negatives,\n",
        "            'false_negatives': false_negatives\n",
        "        }\n",
        "\n",
        "    def precision(self, conf_matrix):\n",
        "        return conf_matrix['true_positives'] / (conf_matrix['true_positives'] + conf_matrix['false_positives'])\n",
        "\n",
        "    def sensitivity_recall(self, conf_matrix):\n",
        "        return conf_matrix['true_positives'] / (conf_matrix['true_positives'] + conf_matrix['false_negatives'])\n",
        "\n",
        "    def negative_predictive(self, conf_matrix):\n",
        "        return conf_matrix['true_negatives'] / (conf_matrix['true_negatives'] + conf_matrix['false_negatives'])\n",
        "\n",
        "    def specificy(self, conf_matrix):\n",
        "        return conf_matrix['true_negatives'] / (conf_matrix['true_negatives'] + conf_matrix['false_positives'])\n",
        "\n",
        "    def f1_scores(self, conf_matrix):\n",
        "        prec = self.precision(conf_matrix)\n",
        "        recall = self.sensitivity_recall(conf_matrix)\n",
        "        return 2 * prec * recall / (prec + recall)\n",
        "\n",
        "    def print_metrics(self):\n",
        "        print(f'jacard index: {self.jacard} \\n')\n",
        "\n",
        "        print(f'precision_land: {self.precision_land}')\n",
        "        print(f'precision_valid: {self.precision_valid}')\n",
        "        print(f'precision_invalid: {self.precision_invalid} \\n')\n",
        "\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_land}')\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_valid}')\n",
        "        print(f'recall_invalid_land: {self.sensitivity_recall_invalid} \\n')\n",
        "\n",
        "        print(f'specificy_invalid_land: {self.specificy_land}')\n",
        "        print(f'specificy_invalid_valid: {self.specificy_valid}')\n",
        "        print(f'specificy_invalid_invalid: {self.specificy_invalid} \\n')\n",
        "\n",
        "        print(f'f1_land: {self.f1_land}')\n",
        "        print(f'f1_invalid: {self.f1_invalid}')\n",
        "        print(f'f1_valid: {self.f1_valid}')\n",
        "\n",
        "        print(f'Training dates: {self.training_dates}, validation dates: {self.validation_dates}, testing dates: {self.testing_dates}')\n",
        "        print(f'Number of run: {self.run_count}, tile_size: {self.tile_size}, step_size: {self.step_size}')\n",
        "\n",
        "    def save_to_file(self):\n",
        "        file_name = f'../metrics/{self.tile_size}_{self.step_size}_{self.run_count}.pkl'\n",
        "        with open(file_name, 'wb') as file:\n",
        "            pickle.dump(self, file)\n",
        "\n",
        "    def get_label_count(self, array):\n",
        "        revert_one_hot = np.argmax(array, (-1))\n",
        "        flatten = np.reshape(revert_one_hot, (-1))\n",
        "        unique_vals, counts = np.unique(flatten, return_counts=True)\n",
        "        label_count = {}\n",
        "        for val, count in zip(unique_vals, counts):\n",
        "            label_count[f'{val}'] = count\n",
        "        return label_count\n",
        "\n",
        "    def get_statistics(self, x_train, x_val, x_test, y_train, y_val, y_test):\n",
        "       return {'y_train': self.get_label_count(y_train),\n",
        "                 'y_val': self.get_label_count(y_val), 'y_test': self.get_label_count(y_test)}\n",
        "    # todo add pixel accuracy\n"
      ],
      "metadata": {
        "id": "r6um1iVpbpix"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this notebook is to evaluate whether tile-overlapping has an effect on the resulting model.\n",
        "We will use the exact same setup as in experiment 1 except for the dataset. Each tile has a size of (256, 256) and the step size is 256 to exclude overlap."
      ],
      "metadata": {
        "collapsed": false,
        "id": "SxwBBw0_wKli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Loading + Preparing Data"
      ],
      "metadata": {
        "id": "TQiNFtcib6wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osm1lHOLb-Is",
        "outputId": "5fad4a27-3e95-4460-857b-60e8adcbb086"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls\n",
        "%cd drive/MyDrive/MachineLearning/Geospatial_ML\n",
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV1KZvqMb_6S",
        "outputId": "9a62662c-7be5-49c7-a9fc-f28d9fbdf75b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n",
            "/content/drive/.shortcut-targets-by-id/15HUD3sGdfvxy5Y_bjvuXgrzwxt7TzRfm/MachineLearning/Geospatial_ML\n",
            "architecture.drawio  evaluation  notebooks     README.md\n",
            "Copy_of_unet.ipynb   models\t prepare_data  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    concatenate,\n",
        "    Conv2DTranspose,\n",
        "    Dropout,\n",
        "    UpSampling2D\n",
        ")\n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle"
      ],
      "metadata": {
        "id": "0FB7ZXQkcKB_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = \"../data_colab/256_256\"\n",
        "\n",
        "y_train  = np.load(os.path.join(data_directory, '2022_06_20.npz'))['y_mask']\n",
        "x_train  = np.load(os.path.join(data_directory, '2022_06_20.npz'))['x_input']\n",
        "\n",
        "y_val = np.load(os.path.join(data_directory, '2022_07_10.npz'))['y_mask']\n",
        "x_val = np.load(os.path.join(data_directory, '2022_07_10.npz'))['x_input']\n",
        "\n",
        "y_test = np.load(os.path.join(data_directory, '2022_07_25.npz'))['y_mask']\n",
        "x_test = np.load(os.path.join(data_directory, '2022_07_25.npz'))['x_input']\n",
        "\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "\n",
        "print(y_val.shape)\n",
        "print(x_val.shape)\n",
        "\n",
        "print(y_test.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6ErV4yBcLs6",
        "outputId": "973fce91-e0e4-4d24-efcb-3b96875e2c4b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(761, 256, 256)\n",
            "(761, 256, 256, 5)\n",
            "(822, 256, 256)\n",
            "(822, 256, 256, 5)\n",
            "(761, 256, 256)\n",
            "(761, 256, 256, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizing(X, y):\n",
        "\n",
        "  print(y.shape)\n",
        "  y_one_hot =  np.array([tf.one_hot(item, depth=3).numpy() for item in y])\n",
        "  print(y_one_hot.shape)\n",
        "  X_normal = X/255\n",
        "  return X_normal, y_one_hot"
      ],
      "metadata": {
        "id": "crUpzYlEcgq5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = normalizing(x_train, y_train)\n",
        "\n",
        "X_val, y_val = normalizing(x_val, y_val)\n",
        "\n",
        "x_test, y_test = normalizing(x_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Q8g6SOcla5",
        "outputId": "4d2246e7-83dc-4625-d3f2-2207911eaa70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(761, 256, 256)\n",
            "(761, 256, 256, 3)\n",
            "(822, 256, 256)\n",
            "(822, 256, 256, 3)\n",
            "(761, 256, 256)\n",
            "(761, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Compiling the model"
      ],
      "metadata": {
        "id": "L87xH5zJcYO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_2d(input_shape, num_classes):\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Downsample layers\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # Upsample layers\n",
        "    up5 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(up5)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    # Output layer\n",
        "    output = Conv2D(num_classes, (1, 1), activation='softmax')(conv7)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=[inputs], outputs=[output])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "cUPkEV0Ic2nz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_2d(input_shape=(256, 256, 5), num_classes=3)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7j2vHOtc4my",
        "outputId": "b6c83806-08ad-471b-86d7-dca7d6f2e15c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 5  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  2944        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 64, 64, 512)  0           ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 64, 64, 768)  0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'conv2d_5[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 64, 64, 256)  1769728     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 25  0          ['conv2d_9[0][0]']               \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 128, 128, 38  0           ['up_sampling2d_1[0][0]',        \n",
            "                                4)                                'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 128, 128, 12  442496      ['concatenate_1[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 128, 128, 12  147584      ['conv2d_10[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_11[0][0]']              \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_2[0][0]',        \n",
            "                                2)                                'conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 256, 256, 64  110656      ['concatenate_2[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 256, 256, 64  36928       ['conv2d_12[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 256, 256, 3)  195         ['conv2d_13[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7,784,195\n",
            "Trainable params: 7,784,195\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Execute trainigs + saving results"
      ],
      "metadata": {
        "id": "R55UTUmGc73x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tile_size = 256\n",
        "step_size = 256\n",
        "saving_path = 'experiment_2'\n",
        "training_dates = '2022_06_20'\n",
        "validation_dates = '2022_07_10'\n",
        "testing_dates = '2022_07_25'"
      ],
      "metadata": {
        "id": "qHDLwE-AftkX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_training(count):\n",
        "  print(f'Start training number {count}')\n",
        "  model = unet_2d(input_shape=(256, 256, 5), num_classes=3)\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=categorical_crossentropy,\n",
        "                metrics=['accuracy']) # ??? alternatives\n",
        "\n",
        "  early_stop = EarlyStopping(monitor='accuracy', patience=5) \n",
        "\n",
        "  model_history = model.fit(x=x_train, y=y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[early_stop])\n",
        "\n",
        "  # saving model\n",
        "  model_name = f'{tile_size}_{step_size}_run_{count}'\n",
        "  model.save(f'../models/{saving_path}/model_{model_name}.h5')\n",
        "\n",
        "  # saving model history\n",
        "  with open(f'../models/{saving_path}/history_{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(model_history.history, file_pi)\n",
        "\n",
        "  # making predictions\n",
        "  pred_test = model.predict(x_test)\n",
        "  pred_val = model.predict(x_val)\n",
        "  pred_train = model.predict(x_train)\n",
        "\n",
        "\n",
        "  # calculating metrics\n",
        "  metrics_test = EvaluationMetrics(x_train, x_val, x_test, y_train, y_val, y_test, pred_test, training_dates, validation_dates, testing_dates, tile_size, step_size, count)\n",
        "  metrics_val = EvaluationMetrics(x_train, x_val, x_test, y_train, y_val, y_val, pred_val, training_dates, validation_dates, testing_dates, tile_size, step_size, count)\n",
        "  metrics_train = EvaluationMetrics(x_train, x_val, x_test, y_train, y_val, y_train, pred_train, training_dates, validation_dates, testing_dates, tile_size, step_size, count)\n",
        "\n",
        "  # saving metrics\n",
        "  with open(f'../metrics/{saving_path}/metrics_test{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(metrics_test, file_pi)\n",
        "  with open(f'../metrics/{saving_path}/metrics_val{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(metrics_val, file_pi)\n",
        "  with open(f'../metrics/{saving_path}/metrics_train{model_name}.pkl', 'wb') as file_pi:\n",
        "      pickle.dump(metrics_train, file_pi)\n",
        "\n",
        "  return metrics_test, metrics_val, metrics_train"
      ],
      "metadata": {
        "id": "lYGEuLXWdKLv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics_test = []\n",
        "all_metrics_val = []\n",
        "all_metrics_train = []\n",
        "\n",
        "\n",
        "for i in range(0,10):\n",
        "  metrics_test, metrics_val, metrics_train = execute_training(i)\n",
        "  all_metrics_test.append(metrics_test)\n",
        "  all_metrics_val.append(metrics_val)\n",
        "  all_metrics_train.append(metrics_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZD4NX8eCffFZ",
        "outputId": "30f1f95f-81c0-49c7-f4cd-fb9a0b9ac1f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training number 0\n",
            "Epoch 1/100\n",
            "24/24 [==============================] - 31s 539ms/step - loss: 0.5011 - accuracy: 0.7933 - val_loss: 21.5792 - val_accuracy: 0.9641\n",
            "Epoch 2/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.1755 - accuracy: 0.9516 - val_loss: 17.0958 - val_accuracy: 0.9680\n",
            "Epoch 3/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.1023 - accuracy: 0.9685 - val_loss: 15.3985 - val_accuracy: 0.9733\n",
            "Epoch 4/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0848 - accuracy: 0.9716 - val_loss: 16.5479 - val_accuracy: 0.9729\n",
            "Epoch 5/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0785 - accuracy: 0.9723 - val_loss: 13.1442 - val_accuracy: 0.9753\n",
            "Epoch 6/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0710 - accuracy: 0.9742 - val_loss: 11.7623 - val_accuracy: 0.9734\n",
            "Epoch 7/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0689 - accuracy: 0.9743 - val_loss: 9.6572 - val_accuracy: 0.9769\n",
            "Epoch 8/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0620 - accuracy: 0.9764 - val_loss: 7.6778 - val_accuracy: 0.9787\n",
            "Epoch 9/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0569 - accuracy: 0.9785 - val_loss: 7.0733 - val_accuracy: 0.9808\n",
            "Epoch 10/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0548 - accuracy: 0.9793 - val_loss: 8.3583 - val_accuracy: 0.9776\n",
            "Epoch 11/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0554 - accuracy: 0.9790 - val_loss: 6.9508 - val_accuracy: 0.9808\n",
            "Epoch 12/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0500 - accuracy: 0.9811 - val_loss: 6.3204 - val_accuracy: 0.9816\n",
            "Epoch 13/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0556 - accuracy: 0.9800 - val_loss: 4.6679 - val_accuracy: 0.9772\n",
            "Epoch 14/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0543 - accuracy: 0.9798 - val_loss: 6.2012 - val_accuracy: 0.9824\n",
            "Epoch 15/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0517 - accuracy: 0.9809 - val_loss: 5.4741 - val_accuracy: 0.9817\n",
            "Epoch 16/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0486 - accuracy: 0.9814 - val_loss: 5.6888 - val_accuracy: 0.9841\n",
            "Epoch 17/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0497 - accuracy: 0.9814 - val_loss: 5.8259 - val_accuracy: 0.9828\n",
            "Epoch 18/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0450 - accuracy: 0.9831 - val_loss: 5.8080 - val_accuracy: 0.9830\n",
            "Epoch 19/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0437 - accuracy: 0.9836 - val_loss: 5.3635 - val_accuracy: 0.9851\n",
            "Epoch 20/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0430 - accuracy: 0.9837 - val_loss: 7.5476 - val_accuracy: 0.9825\n",
            "Epoch 21/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0475 - accuracy: 0.9824 - val_loss: 5.0763 - val_accuracy: 0.9841\n",
            "Epoch 22/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0433 - accuracy: 0.9838 - val_loss: 5.7133 - val_accuracy: 0.9840\n",
            "Epoch 23/100\n",
            "24/24 [==============================] - 6s 261ms/step - loss: 0.0453 - accuracy: 0.9829 - val_loss: 8.0664 - val_accuracy: 0.9823\n",
            "Epoch 24/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0417 - accuracy: 0.9845 - val_loss: 4.9622 - val_accuracy: 0.9850\n",
            "Epoch 25/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0380 - accuracy: 0.9859 - val_loss: 4.0333 - val_accuracy: 0.9864\n",
            "Epoch 26/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0329 - accuracy: 0.9871 - val_loss: 4.1655 - val_accuracy: 0.9860\n",
            "Epoch 27/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0333 - accuracy: 0.9868 - val_loss: 2.9906 - val_accuracy: 0.9873\n",
            "Epoch 28/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0320 - accuracy: 0.9876 - val_loss: 3.5265 - val_accuracy: 0.9863\n",
            "Epoch 29/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0301 - accuracy: 0.9883 - val_loss: 4.4417 - val_accuracy: 0.9871\n",
            "Epoch 30/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0273 - accuracy: 0.9894 - val_loss: 4.2221 - val_accuracy: 0.9850\n",
            "Epoch 31/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0258 - accuracy: 0.9897 - val_loss: 4.0200 - val_accuracy: 0.9880\n",
            "Epoch 32/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0249 - accuracy: 0.9900 - val_loss: 4.3970 - val_accuracy: 0.9870\n",
            "Epoch 33/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0240 - accuracy: 0.9906 - val_loss: 4.4564 - val_accuracy: 0.9863\n",
            "Epoch 34/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0231 - accuracy: 0.9908 - val_loss: 4.8665 - val_accuracy: 0.9870\n",
            "Epoch 35/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0216 - accuracy: 0.9919 - val_loss: 4.1405 - val_accuracy: 0.9869\n",
            "Epoch 36/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0204 - accuracy: 0.9921 - val_loss: 5.2051 - val_accuracy: 0.9868\n",
            "Epoch 37/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0180 - accuracy: 0.9931 - val_loss: 5.4665 - val_accuracy: 0.9872\n",
            "Epoch 38/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0160 - accuracy: 0.9940 - val_loss: 5.9765 - val_accuracy: 0.9869\n",
            "Epoch 39/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0170 - accuracy: 0.9936 - val_loss: 5.7920 - val_accuracy: 0.9879\n",
            "Epoch 40/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0162 - accuracy: 0.9939 - val_loss: 6.9068 - val_accuracy: 0.9868\n",
            "Epoch 41/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 7.6091 - val_accuracy: 0.9852\n",
            "Epoch 42/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 10.5486 - val_accuracy: 0.9809\n",
            "Epoch 43/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0138 - accuracy: 0.9950 - val_loss: 7.6535 - val_accuracy: 0.9868\n",
            "Epoch 44/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 8.0261 - val_accuracy: 0.9880\n",
            "Epoch 45/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 10.5257 - val_accuracy: 0.9859\n",
            "Epoch 46/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 11.4448 - val_accuracy: 0.9858\n",
            "Epoch 47/100\n",
            "24/24 [==============================] - 6s 259ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 10.1638 - val_accuracy: 0.9865\n",
            "Epoch 48/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 9.6065 - val_accuracy: 0.9873\n",
            "Epoch 49/100\n",
            "24/24 [==============================] - 6s 258ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 16.5459 - val_accuracy: 0.9821\n",
            "Epoch 50/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 8.0186 - val_accuracy: 0.9867\n",
            "Epoch 51/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0108 - accuracy: 0.9961 - val_loss: 11.1111 - val_accuracy: 0.9842\n",
            "Epoch 52/100\n",
            "24/24 [==============================] - 6s 260ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 8.1808 - val_accuracy: 0.9860\n",
            "24/24 [==============================] - 2s 62ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b76eb57e8419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmetrics_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mall_metrics_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mall_metrics_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-19cd5c5b7a11>\u001b[0m in \u001b[0;36mexecute_training\u001b[0;34m(count)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m# calculating metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mmetrics_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluationMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0mmetrics_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluationMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mmetrics_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluationMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pred_test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Results"
      ],
      "metadata": {
        "id": "YUcn3V2Fytam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, metric in enumerate(all_metrics_test):\n",
        "  print(f'========= RUN {idx + 1} ============')\n",
        "  print(f'TEST DATA')\n",
        "  metric.print_metrics()\n",
        "  print()\n",
        "  print(f'VALIDATION DATA')\n",
        "  all_metrics_val[idx].print_metrics()\n",
        "  print(f'TRAINING DATA')\n",
        "  all_metrics_train[idx].print_metrics()\n",
        "  print()\n",
        "  print()\n",
        "\n"
      ],
      "metadata": {
        "id": "RbPsYaQn4hEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mean_jacard(all_metrics):\n",
        "  jacard_array = []\n",
        "  for idx, metric in enumerate(all_metrics):\n",
        "    print(metric.jacard)\n",
        "    jacard_array.append(metric.jacard)\n",
        "\n",
        "  print()\n",
        "  print(f'Mean jacard index: {sum(jacard_array)/10}')\n",
        "  print()\n",
        "  print(f'Worst index: {min(jacard_array)}')\n",
        "  print(f'Best index: {max(jacard_array)}')\n",
        "  print(f'Variance: {max(jacard_array)-min(jacard_array)}')\n",
        "\n",
        "print('============ TEST DATA ===================')\n",
        "get_mean_jacard(all_metrics_test)\n",
        "print()\n",
        "\n",
        "print('============ VALIDATION DATA ===================')\n",
        "get_mean_jacard(all_metrics_val)\n",
        "print()\n",
        "\n",
        "print('============ TRAINING DATA ===================')\n",
        "get_mean_jacard(all_metrics_train)\n",
        "print()"
      ],
      "metadata": {
        "id": "4_vk2_Uh4mZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "execution time: ~ 60 min\n",
        "\n",
        "As the mean jacard index is significatly higher and the variance lower compared to the experiment_1 where we used overlap (step_size: 200). We will continue our next experiments without tile overlapping.\n",
        "\n",
        "\n",
        "\n",
        "tf.Tensor(0.955727, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9516739, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.7542591, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9586384, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.85888374, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.97928536, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9624236, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9534589, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.9385002, shape=(), dtype=float32)\n",
        "\n",
        "tf.Tensor(0.97643083, shape=(), dtype=float32)\n",
        "\n",
        "\n",
        "Mean jacard index: 0.9289280772209167\n",
        "\n",
        "Worst index: 0.7542591094970703\n",
        "\n",
        "Best index: 0.9792853593826294\n",
        "\n",
        "Variance: 0.22502624988555908\n",
        "\n",
        "\n",
        "start: 15:25\n",
        "\n"
      ],
      "metadata": {
        "id": "_wz5vZNTywhu"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}