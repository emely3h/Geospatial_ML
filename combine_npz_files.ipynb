{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMjgxNJjggWijGF+DqJi97G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emely3h/Geospatial_ML/blob/feature%2Fadd-data-generators-to-fix-ram-problem/combine_npz_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine npz files\n",
        "\n",
        "This is a notebook for the last step in the prepare data pipeline as we did not have enough RAM to run it locally. To train the model on the entire dataset it is more convenient to have all tile-arrays of all images in one .npz file. "
      ],
      "metadata": {
        "id": "oUgJx7pfMJjO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "m8S-npIwb0bv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd80f703-4c1f-4bf6-b9fe-bfeeb8fa8ad0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/MachineLearning'\n",
            "/content/drive/.shortcut-targets-by-id/15HUD3sGdfvxy5Y_bjvuXgrzwxt7TzRfm/MachineLearning/Geospatial_ML\n",
            "[Errno 2] No such file or directory: 'Geospatial_ML'\n",
            "/content/drive/.shortcut-targets-by-id/15HUD3sGdfvxy5Y_bjvuXgrzwxt7TzRfm/MachineLearning/Geospatial_ML\n",
            "architecture.drawio  colab.py\t       experiments   __pycache__\n",
            "colab-new.py\t     data_exploration  models\t     README.md\n",
            "colab_new.py\t     evaluation        prepare_data  requirements.txt\n"
          ]
        }
      ],
      "source": [
        "#! ls\n",
        "%cd drive/MyDrive/MachineLearning\n",
        "%cd Geospatial_ML\n",
        "! ls"
      ],
      "metadata": {
        "id": "K4ovYlrBb0bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80327c59-ad16-4d4f-c9df-29d131e420d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import datetime\n",
        "data_path = \"../data_colab/256_200\""
      ],
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "m596oOw2b0bz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "uncompressed file is 2GB, 50MB and compressed 274 MB\n",
        "=> loading/ decompressing all arrays takes ~ 15 * 2,04 GB = 31 GB\n",
        "=> loading all images into RAM still works but compressing them fails\n",
        "\n",
        "all 5 images decompressed in memory ~ 18 GB RAM\n",
        "\n",
        "- combining 8 images with savez() takes 20 GB < 5min, < 20GB System RAM\n",
        "- combining 8 images with savez_compressed() takes 1,84 GB > 10min, ~ 30 GB System RAM\n",
        "- trying to combine 11 images with savez_compressed crashed during loading 9th image\n"
      ],
      "metadata": {
        "id": "j1ris5P21Pvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem: running out of ram when trying to save more than 5 images in one compressed npz, crashing always just at the savez_compressed() step\n",
        "# => combining only 5 images into one file and then trying to combine those 2 files if possible\n",
        "# => better way? Why does savez_compressed() consume most RAM?\n",
        "# 50GB not enough for saving 10 images => loading + decompressing images takes ~ 30 GB why does last step, saving take so much RAM?\n",
        "def combine_npz_arrays(data_path):\n",
        "    count = 0\n",
        "    arrays_dict = {}\n",
        "    print(f'Started at: {datetime.datetime.now()}')\n",
        "    for file in os.listdir(data_path):\n",
        "        if file != '2022_08_09.npz' and count < 9: # Todo: find out problem with image 2022_08_09 => crashes when trying to access x_input\n",
        "            print(f'Adding image {file}')\n",
        "            array = np.load(f'{data_path}/{file}')\n",
        "            x_input = array['x_input']\n",
        "            y_mask = array['y_mask']\n",
        "            if len(arrays_dict) < 1:\n",
        "                arrays_dict['x_input'] = x_input\n",
        "                arrays_dict['y_mask'] = y_mask\n",
        "            else:\n",
        "                arrays_dict['x_input'] = np.concatenate((arrays_dict['x_input'], x_input), axis=0)\n",
        "                arrays_dict['y_mask'] = np.concatenate((arrays_dict['y_mask'], y_mask), axis=0)\n",
        "        print(arrays_dict['x_input'].shape)\n",
        "        print(arrays_dict['y_mask'].shape)\n",
        "        print()\n",
        "        count += 1\n",
        "    # test time to execute and file size of np.savez and np.savez_compressed\n",
        "    np.savez_compressed(f'{data_path}/all_images_1', **arrays_dict) #savez_compressed\n",
        "    print('Combined all compressed numpy images into one single file.')\n",
        "    print(f'Finished at: {datetime.datetime.now()}')\n",
        "\n",
        "combine_npz_arrays(\"../data_colab/256_200\")"
      ],
      "metadata": {
        "id": "P2t8Rh1eccZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4216f5-73af-4ad8-94fb-d1453779fa21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started at: 2023-03-28 17:01:23.368041\n",
            "Adding image 2022_10_13.npz\n",
            "(889, 256, 256, 5)\n",
            "(889, 256, 256)\n",
            "\n",
            "Adding image 2022_07_15.npz\n",
            "(1753, 256, 256, 5)\n",
            "(1753, 256, 256)\n",
            "\n",
            "Adding image 2022_09_18.npz\n",
            "(2927, 256, 256, 5)\n",
            "(2927, 256, 256)\n",
            "\n",
            "Adding image 2022_06_20.npz\n",
            "(4178, 256, 256, 5)\n",
            "(4178, 256, 256)\n",
            "\n",
            "Adding image 2022_10_23.npz\n",
            "(5342, 256, 256, 5)\n",
            "(5342, 256, 256)\n",
            "\n",
            "Adding image 2022_07_25.npz\n",
            "(6600, 256, 256, 5)\n",
            "(6600, 256, 256)\n",
            "\n",
            "Adding image 2022_08_04.npz\n",
            "(7919, 256, 256, 5)\n",
            "(7919, 256, 256)\n",
            "\n",
            "Adding image 2022_07_10.npz\n",
            "(9242, 256, 256, 5)\n",
            "(9242, 256, 256)\n",
            "\n",
            "Adding image 2022_07_30.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.load(f'{data_path}/2022_08_09.npz')\n",
        "x_input = array['x_input']\n",
        "y_mask = array['y_mask']\n",
        "print(x_input.shape)\n",
        "print(y_mask.shape)"
      ],
      "metadata": {
        "id": "Au1zMrYWBUCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"../data_colab/256_200\"\n",
        "\n",
        "total_tiles = 0\n",
        "for file in os.listdir(data_path):\n",
        "  if not os.path.isdir(os.path.join(data_path, file)):\n",
        "   \n",
        "    print(f'Image: {file}')\n",
        "    array = np.load(f'{data_path}/{file}')\n",
        "    total_tiles += array['x_input'].shape[0]\n",
        "    print(array['x_input'].shape)\n",
        "    print(array['y_mask'].shape)\n",
        "    print()\n",
        "\n",
        "print(f'Total amount of tiles {total_tiles}')"
      ],
      "metadata": {
        "id": "YW0PJi8Qs6xu",
        "outputId": "70daaea7-d8ea-48ef-973c-b4836c3fd430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 2022_10_13.npz\n",
            "(889, 256, 256, 5)\n",
            "(889, 256, 256)\n",
            "\n",
            "Image: 2022_07_15.npz\n",
            "(864, 256, 256, 5)\n",
            "(864, 256, 256)\n",
            "\n",
            "Image: 2022_09_18.npz\n",
            "(1174, 256, 256, 5)\n",
            "(1174, 256, 256)\n",
            "\n",
            "Image: 2022_06_20.npz\n",
            "(1251, 256, 256, 5)\n",
            "(1251, 256, 256)\n",
            "\n",
            "Image: 2022_10_23.npz\n",
            "(1164, 256, 256, 5)\n",
            "(1164, 256, 256)\n",
            "\n",
            "Image: 2022_07_25.npz\n",
            "(1258, 256, 256, 5)\n",
            "(1258, 256, 256)\n",
            "\n",
            "Image: 2022_08_04.npz\n",
            "(1319, 256, 256, 5)\n",
            "(1319, 256, 256)\n",
            "\n",
            "Image: 2022_07_10.npz\n",
            "(1323, 256, 256, 5)\n",
            "(1323, 256, 256)\n",
            "\n",
            "Image: 2022_07_30.npz\n",
            "(1183, 256, 256, 5)\n",
            "(1183, 256, 256)\n",
            "\n",
            "Image: 2022_08_14.npz\n",
            "(1179, 256, 256, 5)\n",
            "(1179, 256, 256)\n",
            "\n",
            "Image: 2022_08_24.npz\n",
            "(1306, 256, 256, 5)\n",
            "(1306, 256, 256)\n",
            "\n",
            "Image: 2022_09_03.npz\n",
            "(1196, 256, 256, 5)\n",
            "(1196, 256, 256)\n",
            "\n",
            "Image: 2022_12_12.npz\n",
            "(957, 256, 256, 5)\n",
            "(957, 256, 256)\n",
            "\n",
            "Image: 2022_09_08.npz\n",
            "(927, 256, 256, 5)\n",
            "(927, 256, 256)\n",
            "\n",
            "Image: 2022_12_02.npz\n",
            "(1142, 256, 256, 5)\n",
            "(1142, 256, 256)\n",
            "\n",
            "Image: 2022_09_13.npz\n",
            "(1175, 256, 256, 5)\n",
            "(1175, 256, 256)\n",
            "\n",
            "Image: 2022_08_09.npz\n",
            "(1181, 256, 256, 5)\n",
            "(1181, 256, 256)\n",
            "\n",
            "Total amount of tiles 19488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the shape of the output array\n",
        "output_shape = (19488, 256, 256, 5)\n",
        "\n",
        "# Create a memory-mapped array to hold the output data\n",
        "output_file = np.memmap(os.path.join(data_path, \"combined_x_input.npy\"), mode=\"w+\", shape=output_shape, dtype=np.float32)\n",
        "file_count = 0\n",
        "# Iterate over each compressed numpy array\n",
        "for file in os.listdir(data_path):\n",
        "  if not os.path.isdir(os.path.join(data_path, file)) and not file.startswith('combined'):\n",
        "    file_count += 1\n",
        "    print(f'loading file {file_count}: {file}')\n",
        "    # Load the compressed numpy array in chunks using np.memmap\n",
        "    with np.load(os.path.join(data_path, file), mmap_mode=\"r\") as data:\n",
        "        chunk_size = 50  # Number of samples to load per chunk\n",
        "        num_chunks = data[\"x_input\"].shape[0] // chunk_size\n",
        "        for j in range(num_chunks):\n",
        "            print(f'Chunk {j}')\n",
        "            start_idx = (file_count - 1) * num_chunks * chunk_size + j * chunk_size\n",
        "            end_idx = start_idx + chunk_size\n",
        "            # Write the chunk to the output file using the memory-mapped array\n",
        "            output_file[start_idx:end_idx, ...] = data[\"x_input\"][j * chunk_size:(j + 1) * chunk_size, ...]\n",
        "print('finished concatenating arrays')\n",
        "output_file.flush()\n",
        "print('finished flushing')\n",
        "# Delete the memory-mapped array to free up resources\n",
        "del output_file\n",
        "\n",
        "# Problem: file not saved in drive...?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irt8ij7yquS5",
        "outputId": "faf2bd3c-ad86-4fdc-e43c-82b8cf8a246a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading file 1: 2022_06_20.npz\n",
            "Chunk 0\n",
            "Chunk 1\n",
            "Chunk 2\n",
            "Chunk 3\n",
            "Chunk 4\n",
            "Chunk 5\n",
            "Chunk 6\n",
            "Chunk 7\n",
            "Chunk 8\n",
            "Chunk 9\n",
            "Chunk 10\n",
            "Chunk 11\n",
            "Chunk 12\n",
            "Chunk 13\n",
            "Chunk 14\n",
            "Chunk 15\n",
            "Chunk 16\n",
            "Chunk 17\n",
            "Chunk 18\n",
            "Chunk 19\n",
            "Chunk 20\n",
            "Chunk 21\n",
            "Chunk 22\n",
            "Chunk 23\n",
            "Chunk 24\n",
            "loading file 2: 2022_07_10.npz\n",
            "Chunk 0\n",
            "Chunk 1\n",
            "Chunk 2\n",
            "Chunk 3\n",
            "Chunk 4\n",
            "Chunk 5\n",
            "Chunk 6\n",
            "Chunk 7\n",
            "Chunk 8\n",
            "Chunk 9\n",
            "Chunk 10\n",
            "Chunk 11\n",
            "Chunk 12\n",
            "Chunk 13\n",
            "Chunk 14\n",
            "Chunk 15\n",
            "Chunk 16\n",
            "Chunk 17\n",
            "Chunk 18\n",
            "Chunk 19\n",
            "Chunk 20\n",
            "Chunk 21\n",
            "Chunk 22\n",
            "Chunk 23\n",
            "Chunk 24\n",
            "Chunk 25\n",
            "finished concatenating arrays\n",
            "finished flushing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.load(f'{data_path}/combined_x_input.npy')\n",
        "x_input = array['x_input']\n",
        "y_mask = array['y_mask']\n",
        "print(x_input.shape)\n",
        "print(y_mask.shape)"
      ],
      "metadata": {
        "id": "gboBDRWJKwDD",
        "outputId": "ed4a53fe-10d4-4001-ac8b-f93a9b56de10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a291d656a036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_path}/combined_x_input.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x_input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data_colab/256_200/combined_x_input.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls\n",
        "data_path"
      ],
      "metadata": {
        "id": "qiVoiO5ENaDt",
        "outputId": "900351ce-75a6-424e-c4ca-4f3ea4584b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "architecture.drawio  colab.py\t       experiments   __pycache__\n",
            "colab-new.py\t     data_exploration  models\t     README.md\n",
            "colab_new.py\t     evaluation        prepare_data  requirements.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'../data_colab/256_200'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "time to execute npy: 50 min\n",
        "\n",
        "system ram needed: ~10 GB\n",
        "\n",
        "crashed on last img 2022_08_09: ValueError                                Traceback (most recent call last)\n",
        "\n",
        "<ipython-input-19-2ced60a8ab90> in <module>\n",
        "     19             end_idx = start_idx + chunk_size\n",
        "     20             # Write the chunk to the output file using the memory-mapped array\n",
        "---> 21             output_file[start_idx:end_idx, ...] = data[\"x_input\"][j * chunk_size:(j + 1) * chunk_size, ...]\n",
        "     22 \n",
        "     23 # Delete the memory-mapped array to free up resources\n",
        "\n",
        "ValueError: could not broadcast input array from shape (50,256,256,5) into shape (38,256,256,5)\n",
        "\n",
        "\n",
        "\n",
        "file size npz\n",
        "time to execute npz"
      ],
      "metadata": {
        "id": "JGwuVMgb0iRw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "23:43\n",
        "#### 2 images\n",
        "- time npy\n",
        "- file size npy\n",
        "- time npz\n",
        "- file size npz"
      ],
      "metadata": {
        "id": "-uWu40EZLGO1"
      }
    }
  ]
}